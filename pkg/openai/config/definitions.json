[
  {
    "uid": "9fb6a2cb-bff5-4c69-bc6d-4538dd8e3362",
    "id": "ai-openai",
    "title": "OpenAI",
    "documentation_url": "https://www.instill.tech/docs/vdp/ai-connectors/openai",
    "icon": "openai.svg",
    "icon_url": "",
    "spec": {
      "resource_specification": {
        "$schema": "http://json-schema.org/draft-07/schema#",
        "title": "OpenAI AI Connector Spec",
        "type": "object",
        "required": [
          "api_key"
        ],
        "additionalProperties": true,
        "properties": {
          "api_key": {
            "credential_field": true,
            "title": "API Key",
            "description": "Fill your OpenAI API key. To find your keys, visit your OpenAI's API Keys page.",
            "type": "string"
          },
          "organization": {
            "title": "Organization",
            "description": "Specify which organization is used for the requests. Usage will count against the specified organization's subscription quota.",
            "type": "string"
          }
        }
      },
      "component_specification": {
        "$schema": "http://json-schema.org/draft-07/schema#",
        "title": "OpenAI Component Setting",
        "type": "object",
        "properties": {
          "input": {
            "properties": {
              "task": {
                "title": "Task",
                "enum": [
                  "TASK_TEXT_GENERATION",
                  "TASK_TEXT_EMBEDDINGS",
                  "TASK_SPEECH_RECOGNITION"
                ]
              }
            }
          }
        },
        "allOf": [
          {
            "if": {
              "properties": {
                "input": {
                  "properties": {
                    "task": {
                      "const": "TASK_TEXT_GENERATION"
                    }
                  }
                }
              }
            },
            "then": {
              "properties": {
                "metadata": {
                  "title": "Metadata",
                  "type": "object"
                },
                "input": {
                  "type": "object",
                  "required": [
                    "task",
                    "model",
                    "prompt"
                  ],
                  "properties": {
                    "task": {
                      "const": "TASK_TEXT_GENERATION"
                    },
                    "prompt": {
                      "title": "Prompt",
                      "description": "",
                      "instillFormat": "text",
                      "instillUpstreamTypes": [
                        "value",
                        "reference"
                      ],
                      "anyOf": [
                        {
                          "type": "string",
                          "instillUpstreamType": "value"
                        },
                        {
                          "type": "string",
                          "pattern": "^\\{.*\\}$",
                          "instillUpstreamType": "reference"
                        }
                      ]
                    },
                    "model": {
                      "description": "ID of the model to use. See the [model endpoint compatibility](https://platform.openai.com/docs/models/model-endpoint-compatibility) table for details on which models work with the Chat API.",
                      "example": "gpt-3.5-turbo",
                      "anyOf": [
                        {
                          "type": "string"
                        },
                        {
                          "type": "string",
                          "enum": [
                            "gpt-4",
                            "gpt-4-0314",
                            "gpt-4-0613",
                            "gpt-4-32k",
                            "gpt-4-32k-0314",
                            "gpt-4-32k-0613",
                            "gpt-3.5-turbo",
                            "gpt-3.5-turbo-16k",
                            "gpt-3.5-turbo-0301",
                            "gpt-3.5-turbo-0613",
                            "gpt-3.5-turbo-16k-0613"
                          ]
                        }
                      ],
                      "x-oaiTypeLabel": "string",
                      "title": "Model",
                      "instillFormat": "text",
                      "instillUpstreamTypes": [
                        "value",
                        "reference"
                      ]
                    },
                    "system_message": {
                      "title": "System message",
                      "description": "The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. By default, the model\u2019s behavior is using a generic message as \"You are a helpful assistant.\"",
                      "instillFormat": "text",
                      "instillUpstreamTypes": [
                        "value",
                        "reference"
                      ],
                      "anyOf": [
                        {
                          "type": "string",
                          "default": "You are a helpful assistant.",
                          "maxLength": 2048,
                          "instillUpstreamType": "value"
                        },
                        {
                          "type": "string",
                          "pattern": "^\\{.*\\}$",
                          "instillUpstreamType": "reference"
                        }
                      ]
                    },
                    "temperature": {
                      "title": "Temperature",
                      "description": "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n\nWe generally recommend altering this or `top_p` but not both.\n",
                      "instillFormat": "number",
                      "instillUpstreamTypes": [
                        "value",
                        "reference"
                      ],
                      "anyOf": [
                        {
                          "type": "number",
                          "minimum": 0,
                          "maximum": 2,
                          "default": 1,
                          "example": 1,
                          "nullable": true,
                          "instillUpstreamType": "value"
                        },
                        {
                          "type": "string",
                          "pattern": "^\\{.*\\}$",
                          "instillUpstreamType": "reference"
                        }
                      ]
                    },
                    "n": {
                      "title": "N",
                      "description": "How many chat completion choices to generate for each input message.",
                      "instillFormat": "integer",
                      "instillUpstreamTypes": [
                        "value",
                        "reference"
                      ],
                      "anyOf": [
                        {
                          "type": "integer",
                          "minimum": 1,
                          "maximum": 128,
                          "default": 1,
                          "example": 1,
                          "nullable": true,
                          "instillUpstreamType": "value"
                        },
                        {
                          "type": "string",
                          "pattern": "^\\{.*\\}$",
                          "instillUpstreamType": "reference"
                        }
                      ]
                    },
                    "max_tokens": {
                      "title": "Max Tokens",
                      "description": "The maximum number of [tokens](/tokenizer) to generate in the chat completion.\n\nThe total length of input tokens and generated tokens is limited by the model's context length. [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb) for counting tokens.\n",
                      "instillFormat": "integer",
                      "instillUpstreamTypes": [
                        "value",
                        "reference"
                      ],
                      "anyOf": [
                        {
                          "default": "inf",
                          "type": "integer",
                          "instillUpstreamType": "value"
                        },
                        {
                          "type": "string",
                          "pattern": "^\\{.*\\}$",
                          "instillUpstreamType": "reference"
                        }
                      ]
                    }
                  },
                  "title": "Data Flow"
                }
              }
            }
          },
          {
            "if": {
              "properties": {
                "input": {
                  "properties": {
                    "task": {
                      "const": "TASK_TEXT_EMBEDDINGS"
                    }
                  }
                }
              }
            },
            "then": {
              "properties": {
                "metadata": {
                  "title": "Metadata",
                  "type": "object"
                },
                "input": {
                  "type": "object",
                  "required": [
                    "task",
                    "text",
                    "model"
                  ],
                  "properties": {
                    "task": {
                      "const": "TASK_TEXT_EMBEDDINGS"
                    },
                    "text": {
                      "title": "Text",
                      "description": "",
                      "instillFormat": "text",
                      "instillUpstreamTypes": [
                        "value",
                        "reference"
                      ],
                      "anyOf": [
                        {
                          "type": "string",
                          "instillUpstreamType": "value"
                        },
                        {
                          "type": "string",
                          "pattern": "^\\{.*\\}$",
                          "instillUpstreamType": "reference"
                        }
                      ]
                    },
                    "model": {
                      "description": "ID of the model to use. You can use the [List models](https://platform.openai.com/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](https://platform.openai.com/docs/models/overview) for descriptions of them.\n",
                      "example": "text-embedding-ada-002",
                      "anyOf": [
                        {
                          "type": "string"
                        },
                        {
                          "type": "string",
                          "enum": [
                            "text-embedding-ada-002"
                          ]
                        }
                      ],
                      "x-oaiTypeLabel": "string",
                      "title": "Model",
                      "instillFormat": "text",
                      "instillUpstreamTypes": [
                        "value",
                        "reference"
                      ]
                    }
                  },
                  "title": "Data Flow"
                }
              }
            }
          },
          {
            "if": {
              "properties": {
                "input": {
                  "properties": {
                    "task": {
                      "const": "TASK_SPEECH_RECOGNITION"
                    }
                  }
                }
              }
            },
            "then": {
              "properties": {
                "metadata": {
                  "title": "Metadata",
                  "type": "object"
                },
                "input": {
                  "type": "object",
                  "required": [
                    "task",
                    "audio",
                    "model"
                  ],
                  "properties": {
                    "task": {
                      "const": "TASK_SPEECH_RECOGNITION"
                    },
                    "audio": {
                      "title": "Audio",
                      "description": "The audio file object (not file name) to transcribe, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm.\n",
                      "instillFormat": "audio",
                      "instillUpstreamTypes": [
                        "reference"
                      ],
                      "anyOf": [
                        {
                          "type": "string",
                          "pattern": "^\\{.*\\}$",
                          "instillUpstreamType": "reference"
                        }
                      ]
                    },
                    "model": {
                      "description": "ID of the model to use. Only `whisper-1` is currently available.\n",
                      "example": "whisper-1",
                      "anyOf": [
                        {
                          "type": "string"
                        },
                        {
                          "type": "string",
                          "enum": [
                            "whisper-1"
                          ]
                        }
                      ],
                      "x-oaiTypeLabel": "string",
                      "title": "Model",
                      "instillFormat": "text",
                      "instillUpstreamTypes": [
                        "value",
                        "reference"
                      ]
                    },
                    "temperature": {
                      "title": "Temperature",
                      "description": "The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.\n",
                      "instillFormat": "number",
                      "instillUpstreamTypes": [
                        "value",
                        "reference"
                      ],
                      "anyOf": [
                        {
                          "type": "number",
                          "default": 0,
                          "instillUpstreamType": "value"
                        },
                        {
                          "type": "string",
                          "pattern": "^\\{.*\\}$",
                          "instillUpstreamType": "reference"
                        }
                      ]
                    },
                    "language": {
                      "title": "Language",
                      "description": "The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.\n",
                      "instillFormat": "text",
                      "instillUpstreamTypes": [
                        "value",
                        "reference"
                      ],
                      "anyOf": [
                        {
                          "type": "string",
                          "instillUpstreamType": "value"
                        },
                        {
                          "type": "string",
                          "pattern": "^\\{.*\\}$",
                          "instillUpstreamType": "reference"
                        }
                      ]
                    },
                    "prompt": {
                      "title": "Prompt",
                      "description": "An optional text to guide the model's style or continue a previous audio segment. The [prompt](https://platform.openai.com/docs/guides/speech-to-text/prompting) should match the audio language.\n",
                      "instillFormat": "text",
                      "instillUpstreamTypes": [
                        "value",
                        "reference"
                      ],
                      "anyOf": [
                        {
                          "type": "string",
                          "instillUpstreamType": "value"
                        },
                        {
                          "type": "string",
                          "pattern": "^\\{.*\\}$",
                          "instillUpstreamType": "reference"
                        }
                      ]
                    }
                  },
                  "title": "Data Flow"
                }
              }
            }
          }
        ]
      },
      "openapi_specifications": {
        "TASK_TEXT_GENERATION": {
          "openapi": "3.0.0",
          "info": {
            "version": "1.0.0",
            "title": "OpenAI Connector OpenAPI"
          },
          "paths": {
            "/execute": {
              "post": {
                "requestBody": {
                  "required": true,
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "inputs": {
                            "type": "array",
                            "items": {
                              "type": "object",
                              "required": [
                                "task",
                                "model",
                                "prompt"
                              ],
                              "properties": {
                                "task": {
                                  "const": "TASK_TEXT_GENERATION"
                                },
                                "prompt": {
                                  "title": "Prompt",
                                  "type": "string",
                                  "instillFormat": "text",
                                  "instillUpstreamTypes": [
                                    "value",
                                    "reference"
                                  ]
                                },
                                "model": {
                                  "description": "ID of the model to use. See the [model endpoint compatibility](https://platform.openai.com/docs/models/model-endpoint-compatibility) table for details on which models work with the Chat API.",
                                  "example": "gpt-3.5-turbo",
                                  "anyOf": [
                                    {
                                      "type": "string"
                                    },
                                    {
                                      "type": "string",
                                      "enum": [
                                        "gpt-4",
                                        "gpt-4-0314",
                                        "gpt-4-0613",
                                        "gpt-4-32k",
                                        "gpt-4-32k-0314",
                                        "gpt-4-32k-0613",
                                        "gpt-3.5-turbo",
                                        "gpt-3.5-turbo-16k",
                                        "gpt-3.5-turbo-0301",
                                        "gpt-3.5-turbo-0613",
                                        "gpt-3.5-turbo-16k-0613"
                                      ]
                                    }
                                  ],
                                  "x-oaiTypeLabel": "string",
                                  "title": "Model",
                                  "instillFormat": "text",
                                  "instillUpstreamTypes": [
                                    "value",
                                    "reference"
                                  ]
                                },
                                "system_message": {
                                  "title": "System message",
                                  "description": "The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. By default, the model\u2019s behavior is using a generic message as \"You are a helpful assistant.\"",
                                  "type": "string",
                                  "default": "You are a helpful assistant.",
                                  "maxLength": 2048,
                                  "instillFormat": "text",
                                  "instillUpstreamTypes": [
                                    "value",
                                    "reference"
                                  ]
                                },
                                "temperature": {
                                  "type": "number",
                                  "minimum": 0,
                                  "maximum": 2,
                                  "default": 1,
                                  "example": 1,
                                  "nullable": true,
                                  "description": "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n\nWe generally recommend altering this or `top_p` but not both.\n",
                                  "title": "Temperature",
                                  "instillFormat": "number",
                                  "instillUpstreamTypes": [
                                    "value",
                                    "reference"
                                  ]
                                },
                                "n": {
                                  "type": "integer",
                                  "minimum": 1,
                                  "maximum": 128,
                                  "default": 1,
                                  "example": 1,
                                  "nullable": true,
                                  "description": "How many chat completion choices to generate for each input message.",
                                  "title": "N",
                                  "instillFormat": "integer",
                                  "instillUpstreamTypes": [
                                    "value",
                                    "reference"
                                  ]
                                },
                                "max_tokens": {
                                  "description": "The maximum number of [tokens](/tokenizer) to generate in the chat completion.\n\nThe total length of input tokens and generated tokens is limited by the model's context length. [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb) for counting tokens.\n",
                                  "default": "inf",
                                  "type": "integer",
                                  "title": "Max Tokens",
                                  "instillFormat": "integer",
                                  "instillUpstreamTypes": [
                                    "value",
                                    "reference"
                                  ]
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                },
                "responses": {
                  "200": {
                    "description": "",
                    "content": {
                      "application/json": {
                        "schema": {
                          "type": "object",
                          "properties": {
                            "outputs": {
                              "type": "array",
                              "items": {
                                "type": "object",
                                "properties": {
                                  "texts": {
                                    "type": "array",
                                    "items": {
                                      "type": "string",
                                      "instillFormat": "text"
                                    },
                                    "instillFormat": "text_array"
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "TASK_TEXT_EMBEDDINGS": {
          "openapi": "3.0.0",
          "info": {
            "version": "1.0.0",
            "title": "OpenAI Connector OpenAPI"
          },
          "paths": {
            "/execute": {
              "post": {
                "requestBody": {
                  "required": true,
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "inputs": {
                            "type": "array",
                            "items": {
                              "type": "object",
                              "required": [
                                "task",
                                "text",
                                "model"
                              ],
                              "properties": {
                                "task": {
                                  "const": "TASK_TEXT_EMBEDDINGS"
                                },
                                "text": {
                                  "title": "Text",
                                  "type": "string",
                                  "instillFormat": "text",
                                  "instillUpstreamTypes": [
                                    "value",
                                    "reference"
                                  ]
                                },
                                "model": {
                                  "description": "ID of the model to use. You can use the [List models](https://platform.openai.com/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](https://platform.openai.com/docs/models/overview) for descriptions of them.\n",
                                  "example": "text-embedding-ada-002",
                                  "anyOf": [
                                    {
                                      "type": "string"
                                    },
                                    {
                                      "type": "string",
                                      "enum": [
                                        "text-embedding-ada-002"
                                      ]
                                    }
                                  ],
                                  "x-oaiTypeLabel": "string",
                                  "title": "Model",
                                  "instillFormat": "text",
                                  "instillUpstreamTypes": [
                                    "value",
                                    "reference"
                                  ]
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                },
                "responses": {
                  "200": {
                    "description": "",
                    "content": {
                      "application/json": {
                        "schema": {
                          "type": "object",
                          "properties": {
                            "outputs": {
                              "type": "array",
                              "items": {
                                "type": "object",
                                "properties": {
                                  "embedding": {
                                    "type": "array",
                                    "format": "embedding",
                                    "items": {
                                      "type": "number"
                                    },
                                    "instillFormat": "number_array"
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "TASK_SPEECH_RECOGNITION": {
          "openapi": "3.0.0",
          "info": {
            "version": "1.0.0",
            "title": "OpenAI Connector OpenAPI"
          },
          "paths": {
            "/execute": {
              "post": {
                "requestBody": {
                  "required": true,
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "inputs": {
                            "type": "array",
                            "items": {
                              "type": "object",
                              "required": [
                                "task",
                                "audio",
                                "model"
                              ],
                              "properties": {
                                "task": {
                                  "const": "TASK_SPEECH_RECOGNITION"
                                },
                                "audio": {
                                  "description": "The audio file object (not file name) to transcribe, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm.\n",
                                  "type": "string",
                                  "x-oaiTypeLabel": "file",
                                  "format": "binary",
                                  "title": "Audio",
                                  "instillFormat": "audio",
                                  "instillUpstreamTypes": [
                                    "reference"
                                  ]
                                },
                                "model": {
                                  "description": "ID of the model to use. Only `whisper-1` is currently available.\n",
                                  "example": "whisper-1",
                                  "anyOf": [
                                    {
                                      "type": "string"
                                    },
                                    {
                                      "type": "string",
                                      "enum": [
                                        "whisper-1"
                                      ]
                                    }
                                  ],
                                  "x-oaiTypeLabel": "string",
                                  "title": "Model",
                                  "instillFormat": "text",
                                  "instillUpstreamTypes": [
                                    "value",
                                    "reference"
                                  ]
                                },
                                "temperature": {
                                  "description": "The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.\n",
                                  "type": "number",
                                  "default": 0,
                                  "title": "Temperature",
                                  "instillFormat": "number",
                                  "instillUpstreamTypes": [
                                    "value",
                                    "reference"
                                  ]
                                },
                                "language": {
                                  "description": "The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.\n",
                                  "type": "string",
                                  "title": "Language",
                                  "instillFormat": "text",
                                  "instillUpstreamTypes": [
                                    "value",
                                    "reference"
                                  ]
                                },
                                "prompt": {
                                  "description": "An optional text to guide the model's style or continue a previous audio segment. The [prompt](https://platform.openai.com/docs/guides/speech-to-text/prompting) should match the audio language.\n",
                                  "type": "string",
                                  "title": "Prompt",
                                  "instillFormat": "text",
                                  "instillUpstreamTypes": [
                                    "value",
                                    "reference"
                                  ]
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                },
                "responses": {
                  "200": {
                    "description": "",
                    "content": {
                      "application/json": {
                        "schema": {
                          "type": "object",
                          "properties": {
                            "outputs": {
                              "type": "array",
                              "items": {
                                "type": "object",
                                "properties": {
                                  "text": {
                                    "type": "string",
                                    "instillFormat": "text"
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    },
    "public": true,
    "custom": false,
    "vendor_attributes": {
      "githubIssueLabel": "openai",
      "license": "MIT",
      "releaseStage": "alpha",
      "resourceRequirements": {},
      "modelType": "api"
    }
  }
]
